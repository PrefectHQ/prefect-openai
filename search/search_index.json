{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Coordinate and use AI in your dataflow with <code>prefect-openai</code>","text":"<p>The <code>prefect-openai</code> collection makes it easy to leverage the capabilities of AI in your flows. Check out the examples below to get started!</p>"},{"location":"#summarize-tracebacks-with-gpt3","title":"Summarize tracebacks with GPT3","text":"<p>Tracebacks--it's quintessential in programming. They are a record of every line of code leading to the error, to help us, humans, determine what's wrong with the program and find a solution.</p> <p>However, tracebacks can be extraordinarily complex, especially for someone new to the codebase.</p> <p>To streamline this process, we could add AI to the mix, to offer a more human-readable summary of the issue, so it's easier for the developer to understand what went wrong and implement a fix.</p> <p>After installing <code>prefect-openai</code> and saving an OpenAI key, you can easily incorporate OpenAI within your flows to help you achieve the aforementioned benefits!</p> <pre><code>from prefect import flow, get_run_logger\nfrom prefect_openai import OpenAICredentials, CompletionModel\n\n\n@flow\ndef summarize_traceback(traceback: str) -&gt; str:\n    logger = get_run_logger()\n    openai_credentials = OpenAICredentials.load(\"openai-credentials\")\n    completion_model = CompletionModel(\n        openai_credentials=openai_credentials,\n        model=\"text-curie-001\",\n        max_tokens=512,\n    )\n    prompt = f\"Summarize cause of error from this traceback: ```{traceback}```\"\n    summary = completion_model.submit_prompt(traceback).choices[0][\"text\"]\n    logger.info(f\"Summary of the traceback: {summary}\")\n    return summary\n\n\nif __name__ == \"__main__\":\n    traceback = \"\"\"\n        ParameterBindError: Error binding parameters for function 'summarize_traceback': missing a required argument: 'traceback'.\n        Function 'summarize_traceback' has signature 'traceback: str) -&gt; str' but received args: () and kwargs: {}.\n    \"\"\"\n    summarize_traceback(traceback)\n</code></pre> <p><pre><code>...\n12:29:32.085 | INFO    | Flow run 'analytic-starling' - Finished text completion using the 'text-curie-001' model with 113 tokens, creating 1 choice(s).\n12:29:32.089 | INFO    | Flow run 'analytic-starling' - Summary of the traceback:     This error is caused by the missing argument traceback. The function expects a traceback object as its first argument, but received nothing.\n...\n</code></pre> Notice how the original traceback was quite long and confusing.</p> <p>On the flip side, the Curie GPT3 model was able to summarize the issue eloquently!</p>"},{"location":"#create-a-story-around-a-flow-run-name-with-gpt3-and-dall-e","title":"Create a story around a flow run name with GPT3 and DALL-E","text":"<p>Have you marveled at all the AI-generated images and wondered how others did it?</p> <p>After installing <code>prefect-openai</code> and saving an OpenAI key, you, too, can create AI-generated art.</p> <p>Here's an example on how to create a story and an image based off a flow run name.</p> <pre><code>from prefect import flow, task, get_run_logger\nfrom prefect.context import get_run_context\nfrom prefect_openai import OpenAICredentials, ImageModel, CompletionModel\n\n\n@task\ndef create_story_from_name(credentials: OpenAICredentials, flow_run_name: str) -&gt; str:\n\"\"\"\n    Create a fun story about the flow run name.\n    \"\"\"\n    text_model = CompletionModel(\n        openai_credentials=credentials, model=\"text-curie-001\", max_tokens=288\n    )\n    text_prompt = f\"Provide a fun story about a {flow_run_name}\"\n    story = text_model.submit_prompt(text_prompt).choices[0].text.strip()\n    return story\n\n\n@task\ndef create_image_from_story(credentials: OpenAICredentials, story: str) -&gt; str:\n\"\"\"\n    Create an image associated with the story.\n    \"\"\"\n    image_model = ImageModel(openai_credentials=credentials, size=\"512x512\")\n    image_result = image_model.submit_prompt(story)\n    image_url = image_result.data[0][\"url\"]\n    return image_url\n\n\n@flow\ndef create_story_and_image_from_flow_run_name() -&gt; str:\n\"\"\"\n    Get the flow run name and create a story and image associated with it.\n    \"\"\"\n    context = get_run_context()\n    flow_run_name = context.flow_run.name.replace(\"-\", \" \")\n\n    credentials = OpenAICredentials.load(\"openai-credentials\")\n    story = create_story_from_name(credentials=credentials, flow_run_name=flow_run_name)\n    image_url = create_image_from_story(credentials=credentials, story=story)\n\n    story_and_image = (\n        f\"The story about a {flow_run_name}: '{story}' \"\n        f\"And its image: {image_url}\"\n    )\n    print(story_and_image)\n    return story_and_image\n\n\ncreate_story_and_image_from_flow_run_name()\n</code></pre> <p>Visit Flow Run Name Art to see some example output!</p>"},{"location":"#resources","title":"Resources","text":"<p>For more tips on how to use tasks and flows in a Collection, check out Using Collections!</p>"},{"location":"#installation","title":"Installation","text":"<p>Install <code>prefect-openai</code> with <code>pip</code>:</p> <pre><code>pip install prefect-openai\n</code></pre> <p>Requires an installation of Python 3.7+.</p> <p>We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv.</p> <p>These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation.</p>"},{"location":"#saving-an-openai-key","title":"Saving an OpenAI key","text":"<p>It's easy to set up an <code>OpenAICredentials</code> block!</p> <ol> <li>Head over to https://beta.openai.com/account/api-keys</li> <li>Login to your OpenAI account</li> <li>Click \"+ Create new secret key\"</li> <li>Copy the generated API key</li> <li>Create a short script, replacing the placeholders (or do so in the UI)</li> </ol> <pre><code>from prefect_openai import OpenAICredentials`\nOpenAICredentials(api_key=\"API_KEY_PLACEHOLDER\").save(\"BLOCK_NAME_PLACEHOLDER\")\n</code></pre> <p>Congrats! You can now easily load the saved block, which holds your OpenAI API key:</p> <pre><code>from prefect_openai import OpenAICredentials\nOpenAICredentials.load(\"BLOCK_NAME_PLACEHOLDER\")\n</code></pre>"},{"location":"#feedback","title":"Feedback","text":"<p>If you encounter any bugs while using <code>prefect-openai</code>, feel free to open an issue in the prefect-openai repository.</p> <p>If you have any questions or issues while using <code>prefect-openai</code>, you can find help in either the Prefect Discourse forum or the Prefect Slack community.</p> <p>Feel free to star or watch <code>prefect-openai</code> for updates too!</p>"},{"location":"#contributing","title":"Contributing","text":"<p>If you'd like to help contribute to fix an issue or add a feature to <code>prefect-openai</code>, please propose changes through a pull request from a fork of the repository.</p> <p>Here are the steps:</p> <ol> <li>Fork the repository</li> <li>Clone the forked repository</li> <li>Install the repository and its dependencies: <pre><code>pip install -e \".[dev]\"\n</code></pre></li> <li>Make desired changes</li> <li>Add tests</li> <li>Insert an entry to CHANGELOG.md</li> <li>Install <code>pre-commit</code> to perform quality checks prior to commit: <pre><code>pre-commit install\n</code></pre></li> <li><code>git commit</code>, <code>git push</code>, and create a pull request</li> </ol>"},{"location":"blocks_catalog/","title":"Blocks Catalog","text":"<p>Below is a list of Blocks available for registration in <code>prefect-openai</code>.</p> <p>To register blocks in this module to view and edit them on Prefect Cloud: <pre><code>prefect block register -m prefect_openai\n</code></pre> Note, to use the <code>load</code> method on Blocks, you must already have a block document saved through code or saved through the UI.</p>"},{"location":"blocks_catalog/#credentials-module","title":"Credentials Module","text":"<p>OpenAICredentials</p> <p>To load the OpenAICredentials: <pre><code>from prefect import flow\nfrom prefect_openai.credentials import OpenAICredentials\n\n@flow\ndef my_flow():\n    my_block = OpenAICredentials.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre></p>"},{"location":"blocks_catalog/#completion-module","title":"Completion Module","text":"<p>CompletionModel</p> <p>To load the CompletionModel: <pre><code>from prefect import flow\nfrom prefect_openai.completion import CompletionModel\n\n@flow\ndef my_flow():\n    my_block = CompletionModel.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre></p>"},{"location":"blocks_catalog/#image-module","title":"Image Module","text":"<p>ImageModel</p> <p>To load the ImageModel: <pre><code>from prefect import flow\nfrom prefect_openai.image import ImageModel\n\n@flow\ndef my_flow():\n    my_block = ImageModel.load(\"MY_BLOCK_NAME\")\n\nmy_flow()\n</code></pre></p>"},{"location":"completion/","title":"Completion","text":""},{"location":"completion/#prefect_openai.completion","title":"<code>prefect_openai.completion</code>","text":"<p>Module for generating and configuring OpenAI completions.</p>"},{"location":"completion/#prefect_openai.completion-classes","title":"Classes","text":""},{"location":"completion/#prefect_openai.completion.CompletionModel","title":"<code>CompletionModel</code>","text":"<p>         Bases: <code>Block</code></p> <p>A block that contains config for an OpenAI Completion Model. Learn more in the OpenAPI Text Completion docs</p> <p>Attributes:</p> Name Type Description <code>openai_credentials</code> <code>OpenAICredentials</code> <p>The credentials used to authenticate with OpenAI.</p> <code>model</code> <code>Union[Literal[text-davinci-003, text-curie-001, text-babbage-001, text-ada-001], str]</code> <p>ID of the model to use.</p> <code>temperature</code> <code>float</code> <p>What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.</p> <code>max_tokens</code> <code>int</code> <p>The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens cannot exceed the model's context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096).</p> <code>suffix</code> <code>Optional[str]</code> <p>The suffix to append to the prompt.</p> <code>echo</code> <code>bool</code> <p>Echo back the prompt in addition to the completion.</p> <code>timeout</code> <code>Optional[float]</code> <p>The maximum time to wait for the model to warm up.</p> Example <p>Load a configured block: <pre><code>from prefect_openai import CompletionModel\n\ncompletion_model = CompletionModel.load(\"BLOCK_NAME\")\n</code></pre></p> Source code in <code>prefect_openai/completion.py</code> <pre><code>class CompletionModel(Block):\n\"\"\"\n    A block that contains config for an OpenAI Completion Model.\n    Learn more in the [OpenAPI Text Completion docs](\n        https://beta.openai.com/docs/guides/completion)\n\n    Attributes:\n        openai_credentials: The credentials used to authenticate with OpenAI.\n        model: ID of the model to use.\n        temperature: What sampling temperature to use.\n            Higher values means the model will take more risks.\n            Try 0.9 for more creative applications, and 0 (argmax sampling)\n            for ones with a well-defined answer.\n        max_tokens: The maximum number of tokens to generate in the completion.\n            The token count of your prompt plus max_tokens cannot exceed the\n            model's context length. Most models have a context length of 2048 tokens\n            (except for the newest models, which support 4096).\n        suffix: The suffix to append to the prompt.\n        echo: Echo back the prompt in addition to the completion.\n        timeout: The maximum time to wait for the model to warm up.\n\n    Example:\n        Load a configured block:\n        ```python\n        from prefect_openai import CompletionModel\n\n        completion_model = CompletionModel.load(\"BLOCK_NAME\")\n        ```\n    \"\"\"\n\n    openai_credentials: OpenAICredentials = Field(\n        default=..., description=\"The credentials used to authenticate with OpenAI.\"\n    )\n    model: Union[\n        Literal[\n            \"text-davinci-003\", \"text-curie-001\", \"text-babbage-001\", \"text-ada-001\"\n        ],\n        str,\n    ] = Field(default=\"text-curie-001\", description=\"ID of the model to use.\")\n    temperature: float = Field(\n        default=0.5,\n        description=(\n            \"What sampling temperature to use. Higher values means the model will take \"\n            \"more risks. Try 0.9 for more creative applications, and 0 \"\n            \"(argmax sampling) for ones with a well-defined answer.\"\n        ),\n    )\n    max_tokens: int = Field(\n        default=16,\n        description=(\n            \"The maximum number of tokens to generate in the completion. \"\n            \"The token count of your prompt plus max_tokens cannot exceed the \"\n            \"model's context length. Most models have a context length of 2048 tokens \"\n            \"(except for the newest models, which support 4096).\"\n        ),\n    )\n    suffix: Optional[str] = Field(\n        default=None, description=\"The suffix to append to the prompt.\"\n    )\n    echo: bool = Field(default=False, description=\"Whether to echo the prompt.\")\n    timeout: Optional[float] = Field(\n        default=None, description=\"The maximum time to wait for the model to warm up.\"\n    )\n\n    _block_type_name = \"OpenAI Completion Model\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/QE8JwcbZBmIfiognXDLcY/2bcd4c759f877d37159f576101218b49/open-ai-logo-8B9BFEDC26-seeklogo.com.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-openai/completion/#prefect_openai.completion.CompletionModel\"  # noqa\n\n    @property\n    def logger(self) -&gt; Logger:\n\"\"\"\n        Returns a logger based on whether the CompletionModel\n        is called from within a flow or task run context.\n        If a run context is present, the logger property returns a run logger.\n        Else, it returns a default logger labeled with the class's name.\n        Returns:\n            The run logger or a default logger with the class's name.\n        \"\"\"\n        try:\n            return get_run_logger()\n        except MissingContextError:\n            return get_logger(self.__class__.__name__)\n\n    @sync_compatible\n    async def submit_prompt(\n        self, prompt: str, **acreate_kwargs: Dict[str, Any]\n    ) -&gt; OpenAIObject:\n\"\"\"\n        Submits a prompt for the model to generate a text completion.\n        OpenAI will return an object potentially containing multiple `choices`,\n        where the zeroth index is what they consider the \"best\" completion.\n        Learn more in the [OpenAPI Text Completion docs](\n            https://beta.openai.com/docs/guides/completion)\n\n        Args:\n            prompt: The prompt to use for the completion.\n            **acreate_kwargs: Additional keyword arguments to pass\n                to [`openai.Completion.acreate`](\n                https://beta.openai.com/docs/api-reference/completions/create).\n\n        Returns:\n            The OpenAIObject containing the completion and associated metadata.\n\n        Example:\n            Create an OpenAI Completion given a prompt:\n            ```python\n            from prefect import flow\n            from prefect_openai import CompletionModel, OpenAICredentials\n\n            @flow(log_prints=True)\n            def my_ai_bot(model_name: str = \"text-davinci-003\")\n                credentials = OpenAICredentials.load(\"my-openai-creds\")\n\n                completion_model = CompletionModel(\n                    openai_credentials=credentials,\n                )\n\n                for prompt in [\"hi!\", \"what is the meaning of life?\"]:\n                    completion = completion_model.submit_prompt(prompt)\n                    print(completion.choices[0].text)\n            ```\n        \"\"\"\n        client = self.openai_credentials.get_client()\n\n        input_kwargs = dict(\n            model=self.model,\n            temperature=self.temperature,\n            max_tokens=self.max_tokens,\n            suffix=self.suffix,\n            echo=self.echo,\n            timeout=self.timeout,\n        )\n        input_kwargs.update(acreate_kwargs)\n\n        creation = await client.Completion.acreate(prompt=prompt, **input_kwargs)\n        total_tokens = creation.usage[\"total_tokens\"]\n        num_choices = len(creation.choices)\n        self.logger.info(\n            f\"Finished text completion using the {self.model!r} \"\n            f\"model with {total_tokens} tokens, creating {num_choices} choice(s).\"\n        )\n        return creation\n</code></pre>"},{"location":"completion/#prefect_openai.completion.CompletionModel-attributes","title":"Attributes","text":""},{"location":"completion/#prefect_openai.completion.CompletionModel.logger","title":"<code>logger: Logger</code>  <code>property</code>","text":"<p>Returns a logger based on whether the CompletionModel is called from within a flow or task run context. If a run context is present, the logger property returns a run logger. Else, it returns a default logger labeled with the class's name.</p> <p>Returns:</p> Type Description <code>Logger</code> <p>The run logger or a default logger with the class's name.</p>"},{"location":"completion/#prefect_openai.completion.CompletionModel-functions","title":"Functions","text":""},{"location":"completion/#prefect_openai.completion.CompletionModel.submit_prompt","title":"<code>submit_prompt</code>  <code>async</code>","text":"<p>Submits a prompt for the model to generate a text completion. OpenAI will return an object potentially containing multiple <code>choices</code>, where the zeroth index is what they consider the \"best\" completion. Learn more in the OpenAPI Text Completion docs</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use for the completion.</p> required <code>**acreate_kwargs</code> <code>Dict[str, Any]</code> <p>Additional keyword arguments to pass to <code>openai.Completion.acreate</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>OpenAIObject</code> <p>The OpenAIObject containing the completion and associated metadata.</p> Example <p>Create an OpenAI Completion given a prompt: <pre><code>from prefect import flow\nfrom prefect_openai import CompletionModel, OpenAICredentials\n\n@flow(log_prints=True)\ndef my_ai_bot(model_name: str = \"text-davinci-003\")\n    credentials = OpenAICredentials.load(\"my-openai-creds\")\n\n    completion_model = CompletionModel(\n        openai_credentials=credentials,\n    )\n\n    for prompt in [\"hi!\", \"what is the meaning of life?\"]:\n        completion = completion_model.submit_prompt(prompt)\n        print(completion.choices[0].text)\n</code></pre></p> Source code in <code>prefect_openai/completion.py</code> <pre><code>@sync_compatible\nasync def submit_prompt(\n    self, prompt: str, **acreate_kwargs: Dict[str, Any]\n) -&gt; OpenAIObject:\n\"\"\"\n    Submits a prompt for the model to generate a text completion.\n    OpenAI will return an object potentially containing multiple `choices`,\n    where the zeroth index is what they consider the \"best\" completion.\n    Learn more in the [OpenAPI Text Completion docs](\n        https://beta.openai.com/docs/guides/completion)\n\n    Args:\n        prompt: The prompt to use for the completion.\n        **acreate_kwargs: Additional keyword arguments to pass\n            to [`openai.Completion.acreate`](\n            https://beta.openai.com/docs/api-reference/completions/create).\n\n    Returns:\n        The OpenAIObject containing the completion and associated metadata.\n\n    Example:\n        Create an OpenAI Completion given a prompt:\n        ```python\n        from prefect import flow\n        from prefect_openai import CompletionModel, OpenAICredentials\n\n        @flow(log_prints=True)\n        def my_ai_bot(model_name: str = \"text-davinci-003\")\n            credentials = OpenAICredentials.load(\"my-openai-creds\")\n\n            completion_model = CompletionModel(\n                openai_credentials=credentials,\n            )\n\n            for prompt in [\"hi!\", \"what is the meaning of life?\"]:\n                completion = completion_model.submit_prompt(prompt)\n                print(completion.choices[0].text)\n        ```\n    \"\"\"\n    client = self.openai_credentials.get_client()\n\n    input_kwargs = dict(\n        model=self.model,\n        temperature=self.temperature,\n        max_tokens=self.max_tokens,\n        suffix=self.suffix,\n        echo=self.echo,\n        timeout=self.timeout,\n    )\n    input_kwargs.update(acreate_kwargs)\n\n    creation = await client.Completion.acreate(prompt=prompt, **input_kwargs)\n    total_tokens = creation.usage[\"total_tokens\"]\n    num_choices = len(creation.choices)\n    self.logger.info(\n        f\"Finished text completion using the {self.model!r} \"\n        f\"model with {total_tokens} tokens, creating {num_choices} choice(s).\"\n    )\n    return creation\n</code></pre>"},{"location":"credentials/","title":"Credentials","text":""},{"location":"credentials/#prefect_openai.credentials","title":"<code>prefect_openai.credentials</code>","text":"<p>Module for authenticating with OpenAI.</p>"},{"location":"credentials/#prefect_openai.credentials-classes","title":"Classes","text":""},{"location":"credentials/#prefect_openai.credentials.OpenAICredentials","title":"<code>OpenAICredentials</code>","text":"<p>         Bases: <code>CredentialsBlock</code></p> <p>Credentials used to authenticate with OpenAI.</p> <p>Attributes:</p> Name Type Description <code>api_key</code> <code>SecretStr</code> <p>The API key used to authenticate with OpenAI.</p> Example <p>Load a configured block: <pre><code>from prefect_openai import OpenAICredentials\n\ncredentials = OpenAICredentials.load(\"BLOCK_NAME\")\n</code></pre></p> Source code in <code>prefect_openai/credentials.py</code> <pre><code>class OpenAICredentials(CredentialsBlock):\n\"\"\"\n    Credentials used to authenticate with OpenAI.\n\n    Attributes:\n        api_key: The API key used to authenticate with OpenAI.\n\n    Example:\n        Load a configured block:\n        ```python\n        from prefect_openai import OpenAICredentials\n\n        credentials = OpenAICredentials.load(\"BLOCK_NAME\")\n        ```\n    \"\"\"\n\n    _block_type_name = \"OpenAI Credentials\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/QE8JwcbZBmIfiognXDLcY/2bcd4c759f877d37159f576101218b49/open-ai-logo-8B9BFEDC26-seeklogo.com.png?h=250\"  # noqa\n    _documentation_url = \"https://prefecthq.github.io/prefect-openai/credentials/#prefect_openai.credentials.OpenAICredentials\"  # noqa\n\n    api_key: SecretStr = Field(\n        default=...,\n        title=\"API Key\",\n        description=\"The API key used to authenticate with OpenAI.\",\n    )\n\n    organization: Optional[str] = Field(\n        default=None,\n        title=\"Organization\",\n        description=\"Specify which organization is used for an API request.\",\n    )\n\n    def get_client(self) -&gt; ModuleType:\n\"\"\"\n        Gets the OpenAPI client.\n\n        Returns:\n            The OpenAPI client.\n        \"\"\"\n        openai.api_key = self.api_key.get_secret_value()\n        openai.organization = self.organization\n        return openai\n</code></pre>"},{"location":"credentials/#prefect_openai.credentials.OpenAICredentials-functions","title":"Functions","text":""},{"location":"credentials/#prefect_openai.credentials.OpenAICredentials.get_client","title":"<code>get_client</code>","text":"<p>Gets the OpenAPI client.</p> <p>Returns:</p> Type Description <code>ModuleType</code> <p>The OpenAPI client.</p> Source code in <code>prefect_openai/credentials.py</code> <pre><code>def get_client(self) -&gt; ModuleType:\n\"\"\"\n    Gets the OpenAPI client.\n\n    Returns:\n        The OpenAPI client.\n    \"\"\"\n    openai.api_key = self.api_key.get_secret_value()\n    openai.organization = self.organization\n    return openai\n</code></pre>"},{"location":"examples_catalog/","title":"Examples Catalog","text":"<p>Below is a list of examples for <code>prefect-openai</code>.</p>"},{"location":"examples_catalog/#completion-module","title":"Completion Module","text":"<p>Create an OpenAI Completion given a prompt: <pre><code>from prefect import flow\nfrom prefect_openai import CompletionModel, OpenAICredentials\n\n@flow(log_prints=True)\ndef my_ai_bot(model_name: str = \"text-davinci-003\")\n    credentials = OpenAICredentials.load(\"my-openai-creds\")\n\n    completion_model = CompletionModel(\n        openai_credentials=credentials,\n    )\n\n    for prompt in [\"hi!\", \"what is the meaning of life?\"]:\n        completion = completion_model.submit_prompt(prompt)\n        print(completion.choices[0].text)\n</code></pre></p>"},{"location":"examples_catalog/#image-module","title":"Image Module","text":"<p>Create an OpenAI Image given a prompt: <pre><code>from prefect_openai import ImageModel\n\nimage_model = ImageModel.load(\"BLOCK_NAME\")\nimage_model.submit_prompt(prompt=\"A prompt for an image.\")\n</code></pre></p>"},{"location":"flow_run_name_art/","title":"Flow Run Name Art","text":"<p>Below are some fun stories and images based off flow run names, created using <code>prefect-openai</code>, GPT3, and DALL-E.</p> <p>To create one, you can follow this tutorial here!</p> <p>If you'd like to share, please feel free to make a pull request:</p> <ul> <li>Create a new heading with the flow run name</li> <li>Copy and paste the story</li> <li>Copy and paste the image</li> </ul> <p>We'd love to see it!</p>"},{"location":"flow_run_name_art/#malachite-mule","title":"Malachite Mule","text":"<p>Malachite is a mule that was born with a unique ability. She can change her color at will, and she loves to play with her color changing friends.</p> <p></p>"},{"location":"flow_run_name_art/#witty-jaybird","title":"Witty Jaybird","text":"<p>Jaybird was always one to think on his feet. He could come up with the funniest jokes and say the smartest things. He was always the life of the party. But sometimes, Jaybird's quick wit can get him into trouble.</p> <p></p>"},{"location":"image/","title":"Image","text":""},{"location":"image/#prefect_openai.image","title":"<code>prefect_openai.image</code>","text":"<p>Module for generating and configuring OpenAI images.</p>"},{"location":"image/#prefect_openai.image-classes","title":"Classes","text":""},{"location":"image/#prefect_openai.image.ImageModel","title":"<code>ImageModel</code>","text":"<p>         Bases: <code>Block</code></p> <p>A block that contains config for an OpenAI Image Model. Learn more in the OpenAPI Image generation docs</p> <p>Attributes:</p> Name Type Description <code>openai_credentials</code> <code>OpenAICredentials</code> <p>The credentials used to authenticate with OpenAI.</p> <code>size</code> <code>Literal[256x256, 512x512, 1024x1024]</code> <p>The size of the image to generate.</p> <code>n</code> <code>int</code> <p>The number of images to generate.</p> <code>response_format</code> <code>Literal[url, b64_json]</code> <p>The format of the image to generate.</p> Example <p>Load a configured block: <pre><code>from prefect_openai import ImageModel\n\nimage_model = ImageModel.load(\"BLOCK_NAME\")\n</code></pre></p> Source code in <code>prefect_openai/image.py</code> <pre><code>class ImageModel(Block):\n\"\"\"\n    A block that contains config for an OpenAI Image Model.\n    Learn more in the [OpenAPI Image generation docs](\n        https://beta.openai.com/docs/guides/images)\n\n    Attributes:\n        openai_credentials: The credentials used to authenticate with OpenAI.\n        size: The size of the image to generate.\n        n: The number of images to generate.\n        response_format: The format of the image to generate.\n\n    Example:\n        Load a configured block:\n        ```python\n        from prefect_openai import ImageModel\n\n        image_model = ImageModel.load(\"BLOCK_NAME\")\n        ```\n    \"\"\"\n\n    openai_credentials: OpenAICredentials = Field(\n        default=..., description=\"The credentials used to authenticate with OpenAI.\"\n    )\n    size: Literal[\"256x256\", \"512x512\", \"1024x1024\"] = Field(\n        default=\"256x256\", description=\"The size of the image to generate.\"\n    )\n    n: int = Field(\n        default=1,\n        title=\"Number of images\",\n        description=\"The number of images to generate.\",\n    )\n    response_format: Literal[\"url\", \"b64_json\"] = Field(\n        default=\"url\", description=\"The format of the image to generate.\"\n    )\n\n    _block_type_name = \"OpenAI Image Model\"\n    _logo_url = \"https://images.ctfassets.net/gm98wzqotmnx/QE8JwcbZBmIfiognXDLcY/2bcd4c759f877d37159f576101218b49/open-ai-logo-8B9BFEDC26-seeklogo.com.png?h=250\"  # noqa\n\n    @property\n    def logger(self) -&gt; Logger:\n\"\"\"\n        Returns a logger based on whether the ImageModel\n        is called from within a flow or task run context.\n        If a run context is present, the logger property returns a run logger.\n        Else, it returns a default logger labeled with the class's name.\n\n        Returns:\n            The run logger or a default logger with the class's name.\n        \"\"\"\n        try:\n            return get_run_logger()\n        except MissingContextError:\n            return get_logger(self.__class__.__name__)\n\n    @sync_compatible\n    async def submit_prompt(\n        self, prompt: str, **acreate_kwargs: Dict[str, Any]\n    ) -&gt; OpenAIObject:\n\"\"\"\n        Submits a prompt for the model to generate an image.\n        Learn more in the [OpenAPI Image generation docs](\n            https://beta.openai.com/docs/guides/images)\n\n        Args:\n            prompt: The prompt to use for the image.\n            **acreate_kwargs: Additional keyword arguments to pass\n                to [`openai.Image.acreate`](\n                https://beta.openai.com/docs/api-reference/images/create).\n\n        Returns:\n            The OpenAIObject containing the image and associated metadata.\n\n        Example:\n            Create an OpenAI Image given a prompt:\n            ```python\n            from prefect_openai import ImageModel\n\n            image_model = ImageModel.load(\"BLOCK_NAME\")\n            image_model.submit_prompt(prompt=\"A prompt for an image.\")\n            ```\n        \"\"\"\n        client = self.openai_credentials.get_client()\n\n        input_kwargs = dict(\n            size=self.size,\n            n=self.n,\n            response_format=self.response_format,\n        )\n        input_kwargs.update(acreate_kwargs)\n        creation = await client.Image.acreate(prompt=prompt, **input_kwargs)\n        self.logger.info(\n            f\"Finished image completion, creating \" f\"{self.n} {self.size!r} image(s).\"\n        )\n        return creation\n</code></pre>"},{"location":"image/#prefect_openai.image.ImageModel-attributes","title":"Attributes","text":""},{"location":"image/#prefect_openai.image.ImageModel.logger","title":"<code>logger: Logger</code>  <code>property</code>","text":"<p>Returns a logger based on whether the ImageModel is called from within a flow or task run context. If a run context is present, the logger property returns a run logger. Else, it returns a default logger labeled with the class's name.</p> <p>Returns:</p> Type Description <code>Logger</code> <p>The run logger or a default logger with the class's name.</p>"},{"location":"image/#prefect_openai.image.ImageModel-functions","title":"Functions","text":""},{"location":"image/#prefect_openai.image.ImageModel.submit_prompt","title":"<code>submit_prompt</code>  <code>async</code>","text":"<p>Submits a prompt for the model to generate an image. Learn more in the OpenAPI Image generation docs</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use for the image.</p> required <code>**acreate_kwargs</code> <code>Dict[str, Any]</code> <p>Additional keyword arguments to pass to <code>openai.Image.acreate</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>OpenAIObject</code> <p>The OpenAIObject containing the image and associated metadata.</p> Example <p>Create an OpenAI Image given a prompt: <pre><code>from prefect_openai import ImageModel\n\nimage_model = ImageModel.load(\"BLOCK_NAME\")\nimage_model.submit_prompt(prompt=\"A prompt for an image.\")\n</code></pre></p> Source code in <code>prefect_openai/image.py</code> <pre><code>@sync_compatible\nasync def submit_prompt(\n    self, prompt: str, **acreate_kwargs: Dict[str, Any]\n) -&gt; OpenAIObject:\n\"\"\"\n    Submits a prompt for the model to generate an image.\n    Learn more in the [OpenAPI Image generation docs](\n        https://beta.openai.com/docs/guides/images)\n\n    Args:\n        prompt: The prompt to use for the image.\n        **acreate_kwargs: Additional keyword arguments to pass\n            to [`openai.Image.acreate`](\n            https://beta.openai.com/docs/api-reference/images/create).\n\n    Returns:\n        The OpenAIObject containing the image and associated metadata.\n\n    Example:\n        Create an OpenAI Image given a prompt:\n        ```python\n        from prefect_openai import ImageModel\n\n        image_model = ImageModel.load(\"BLOCK_NAME\")\n        image_model.submit_prompt(prompt=\"A prompt for an image.\")\n        ```\n    \"\"\"\n    client = self.openai_credentials.get_client()\n\n    input_kwargs = dict(\n        size=self.size,\n        n=self.n,\n        response_format=self.response_format,\n    )\n    input_kwargs.update(acreate_kwargs)\n    creation = await client.Image.acreate(prompt=prompt, **input_kwargs)\n    self.logger.info(\n        f\"Finished image completion, creating \" f\"{self.n} {self.size!r} image(s).\"\n    )\n    return creation\n</code></pre>"}]}